One of the main steps of a cuda program is copying objects from the host memory to device memory (ie gpu) so as to be operated up on be a desired kernel.
These transfers are not trivial especially when they arenon-primitive/native types i.e when they are instances of classes(objects). Things get more complicated when  classes are "composed" especially with pointers to objects of another classes. One workaround is to use cuda's unified/virtual memory paradigm where both host and device memory is virtually unified. The memory allocation use cudaMallocManaged and this virtual memmory pardigm takes care of transfers under the hood as in ../gpuEvo
